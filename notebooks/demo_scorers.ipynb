{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use Scorers\n",
    "This demo includes how to use scorers to get same size scores for each score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "import sys\n",
    "sys.path.insert(0,\"../\")\n",
    "from pytorchpruner.scorers import magnitudeScorer,gradientScorer,hessianScorer\n",
    "\n",
    "TOLERANCE = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      " 0.3538  0.9319\n",
      " 0.1769  0.5440\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "\n",
      " 0.2656  0.0000\n",
      " 0.3695  0.0313\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# We have 4 random parameters\n",
    "w = Parameter(torch.rand(2,2))\n",
    "print(w)\n",
    "\n",
    "def L2d(w):\n",
    "    '''\n",
    "    A custom loss function\n",
    "        w00 w01\n",
    "        w10 w11\n",
    "    '''    \n",
    "    return (w[1,0]**2)*w[1,1]+4*(w[0,0]**3)*w[1,0]\n",
    "\n",
    "def G2d(w):\n",
    "    #Jacobian of the L(w)\n",
    "    wd = w.data\n",
    "    return torch.Tensor([\n",
    "                         [12*(wd[0,0]**2)*wd[1,0],\n",
    "                          0],\n",
    "                         [2*wd[1,0]*wd[1,1]+4*(wd[0,0]**3),\n",
    "                          wd[1,0]**2]\n",
    "                        ])\n",
    "\n",
    "#torch.autograd\n",
    "loss_val = L2d(w)\n",
    "grad_score = gradientScorer(loss_val, w)\n",
    "print(grad_score)\n",
    "#emprical gradient\n",
    "correct_score = G2d(w)\n",
    "# print(correct_score)\n",
    "print((grad_score-correct_score).abs().sum() < TOLERANCE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 3.0034  0.0000\n",
      " 2.9434  0.3537\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "hessian_score = hessianScorer(loss_val,w)\n",
    "\n",
    "print(hessian_score)\n",
    "def H2dScore(w):\n",
    "    #Hessian of the L2(w)\n",
    "    wd=w.data\n",
    "    gw12 = 2*wd[1,0]\n",
    "    gw13 = 12*(wd[0,0]**2)\n",
    "    gw23 = 0\n",
    "    gw11 = 2*wd[1,1]\n",
    "    gw22 = 0\n",
    "    gw33 = 24*wd[0,0]*wd[1,0]\n",
    "    ## x3 0\n",
    "    ## x1 x2\n",
    "    return torch.Tensor([[gw33+0+gw13+gw23, #0,0,: #x3 with others\n",
    "                       0+0+0+0], #0,1,:\n",
    "                      [gw13+0+gw11+gw12, #1,0,: #x1 with others\n",
    "                       gw23+0+gw12+gw22]]) #1,1,: #x2 with others\n",
    "\n",
    "correct_score = H2dScore( w)\n",
    "print((correct_score-hessian_score).abs().sum() < TOLERANCE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
